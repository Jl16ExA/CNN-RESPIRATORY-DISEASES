{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b9ffae47fd084a2c99fb55c45b0c0257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79fb7c86c54e4d42a6e479e91d6623f7",
              "IPY_MODEL_3e55477487e5458981357042aefd865d"
            ],
            "layout": "IPY_MODEL_31f8e2ab07cf41d4b3542f992eaaa117"
          }
        },
        "79fb7c86c54e4d42a6e479e91d6623f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f974825c0d5d4b2da301dc74e7e52f5c",
            "placeholder": "​",
            "style": "IPY_MODEL_7eb85cdc856e4413818e699305d9e673",
            "value": "0.013 MB of 0.013 MB uploaded\r"
          }
        },
        "3e55477487e5458981357042aefd865d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62c8e14b62464e4e86b54cf1f25c4e5b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a63ddf2861742cf954b97e95cc813a5",
            "value": 1
          }
        },
        "31f8e2ab07cf41d4b3542f992eaaa117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f974825c0d5d4b2da301dc74e7e52f5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eb85cdc856e4413818e699305d9e673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62c8e14b62464e4e86b54cf1f25c4e5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a63ddf2861742cf954b97e95cc813a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Mount Google Drive and Install Dependencies\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install mlflow tensorflow wandb\n",
        "\n",
        "# 2. Import Libraries\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "import mlflow\n",
        "import mlflow.tensorflow\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXT0D5vtnLh5",
        "outputId": "b1552f6a-aed5-45a0-f52c-b081f1f57c87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.10/dist-packages (2.15.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.17.7)\n",
            "Requirement already satisfied: mlflow-skinny==2.15.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.15.1)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.2)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.3)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.6)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.26.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.1.4)\n",
            "Requirement already satisfied: pyarrow<16,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (14.0.2)\n",
            "Requirement already satisfied: querystring-parser<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.4)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.3.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.32)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Requirement already satisfied: gunicorn<23 in /usr/local/lib/python3.10/dist-packages (from mlflow) (22.0.0)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.15.1->mlflow) (5.4.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.15.1->mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.15.1->mlflow) (2.2.1)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.15.1->mlflow) (0.30.0)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.15.1->mlflow) (0.4)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.15.1->mlflow) (3.1.43)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.15.1->mlflow) (7.2.1)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.15.1->mlflow) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.15.1->mlflow) (1.26.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.15.1->mlflow) (24.1)\n",
            "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.15.1->mlflow) (3.20.3)\n",
            "Requirement already satisfied: pytz<2025 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.15.1->mlflow) (2024.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.15.1->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.15.1->mlflow) (2.32.3)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.15.1->mlflow) (0.5.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.13.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.0.7)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.15.1->mlflow) (4.0.11)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: aniso8601<10,>=8 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (9.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.15.1->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.15.1->mlflow) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.15.1->mlflow) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow) (2.27.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.15.1->mlflow) (5.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow-skinny==2.15.1->mlflow) (3.19.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.15.1->mlflow) (1.2.14)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.47b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.15.1->mlflow) (0.47b0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow) (4.9)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow) (0.6.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjd-lopez160\u001b[0m (\u001b[33mjd-lopez160-pontificia-universidad-javeriana\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Define Data Directories\n",
        "dir_covid = \"/content/drive/MyDrive/Proyecto 1/Imagenes Proyecto 1/Procesadas/Covid/est_y_norm_Procesadas/\"\n",
        "dir_pneumonia = \"/content/drive/MyDrive/Proyecto 1/Imagenes Proyecto 1/Procesadas/Pneumonia/est_y_norm_Procesadas/\"\n",
        "dir_normal = \"/content/drive/MyDrive/Proyecto 1/Imagenes Proyecto 1/Procesadas/Normal/est_y_norm_Procesadas/\"\n",
        "\n",
        "# 7. Load Data in Batches\n",
        "def load_data_in_batches(directory, label, batch_size=100):\n",
        "    print(f\"Cargando datos de {directory} con etiqueta {label}\")\n",
        "    files = os.listdir(directory)\n",
        "    print(f\"Total de archivos en {directory}: {len(files)}\")  # Imprime la cantidad total de archivos\n",
        "\n",
        "    image_print_limit = 2  # Limita el número de imágenes para las cuales se imprime la dimensión\n",
        "    batch_print_limit = 1  # Limita el número de lotes para los cuales se imprime la dimensión\n",
        "\n",
        "    image_print_count = 0\n",
        "    batch_print_count = 0\n",
        "\n",
        "    while True:\n",
        "        np.random.shuffle(files)\n",
        "        for i in range(0, len(files), batch_size):\n",
        "            batch_files = files[i:i + batch_size]\n",
        "            batch_data = []\n",
        "            for f in batch_files:\n",
        "                img = np.load(os.path.join(directory, f))\n",
        "                if img.ndim == 2:\n",
        "                    img = np.stack([img] * 3, axis=-1)  # Convertir imágenes en escala de grises a RGB\n",
        "                img = tf.image.resize(img, (299, 299))  # Redimensionar la imagen a 299x299\n",
        "                batch_data.append(img)\n",
        "                if image_print_count < image_print_limit:\n",
        "                    print(f\"Dimensiones de la imagen {f} después de redimensionar: {img.shape}\")  # Imprime las dimensiones de algunas imágenes redimensionadas\n",
        "                    image_print_count += 1\n",
        "            batch_data = np.stack(batch_data, axis=0)\n",
        "            batch_labels = np.array([label] * len(batch_files))\n",
        "            if batch_print_count < batch_print_limit:\n",
        "                print(f\"Lote de datos dimensiones: {batch_data.shape}, Lote de etiquetas dimensiones: {batch_labels.shape}\")  # Imprime las dimensiones de algunos lotes\n",
        "                batch_print_count += 1\n",
        "            yield batch_data, batch_labels\n",
        "\n",
        "# 9. Prepare Data for Scenarios\n",
        "def prepare_data_for_scenario(scenario, covid_dir, pneumonia_dir, normal_dir, batch_size=100):\n",
        "    covid_dataset = load_data_in_batches(covid_dir, 0, batch_size)\n",
        "    pneumonia_dataset = load_data_in_batches(pneumonia_dir, 1, batch_size)\n",
        "    normal_dataset = load_data_in_batches(normal_dir, 2, batch_size)\n",
        "\n",
        "    if scenario == 'undersampling':\n",
        "        min_size = min(len(os.listdir(covid_dir)), len(os.listdir(pneumonia_dir)))\n",
        "        normal_dataset = (data for i, (data, label) in enumerate(normal_dataset) if i < min_size)\n",
        "    elif scenario == 'oversampling':\n",
        "        max_size = max(len(os.listdir(covid_dir), len(os.listdir(pneumonia_dir)), len(os.listdir(normal_dir))))\n",
        "        covid_dataset = (data for _ in range(max_size // len(os.listdir(covid_dir)) + 1) for data, label in covid_dataset)\n",
        "        pneumonia_dataset = (data for _ in range(max_size // len(os.listdir(pneumonia_dir)) + 1) for data, label in pneumonia_dataset)\n",
        "\n",
        "    def one_hot_encode(labels, num_classes=3):\n",
        "        return tf.one_hot(labels, num_classes)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_generator(\n",
        "        lambda: (batch for gen in [covid_dataset, pneumonia_dataset, normal_dataset] for batch in gen),\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    dataset = dataset.map(lambda x, y: (x, one_hot_encode(y)))\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    # Print dataset shape (for only one batch)\n",
        "    for data, labels in dataset.take(1):\n",
        "        print(f\"Dimensiones del dataset: {data.shape}, Dimensiones de las etiquetas: {labels.shape}\")\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# 8. Build and Compile Model\n",
        "def build_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(299, 299, 3)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(512, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(512, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(4096, activation='relu'),\n",
        "        layers.Dense(4096, activation='relu'),\n",
        "        layers.Dense(3, activation='softmax')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "pPL0HDdGdRv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(train_dataset, val_dataset, learning_rates, optimizers, epochs=20, scenario=\"original\"):\n",
        "    results = []\n",
        "    num_classes = 3  # Assuming 3 classes: COVID, Pneumonia, Normal\n",
        "    print(f\"Starting experiments for scenario: {scenario}\")\n",
        "    for lr in learning_rates:\n",
        "        for optimizer_class in optimizers:\n",
        "            print(f\"\\nInitializing experiment with Learning Rate: {lr}, Optimizer: {optimizer_class.__name__}\")\n",
        "            wandb.init(project=\"cnn-proyecto-1-ml\",\n",
        "                       config={\n",
        "                           \"learning_rate\": lr,\n",
        "                           \"epochs\": epochs,\n",
        "                           \"optimizer\": optimizer_class.__name__,\n",
        "                           \"scenario\": scenario\n",
        "                       })\n",
        "\n",
        "            model = build_model()\n",
        "            optimizer = optimizer_class(learning_rate=lr)\n",
        "            model.compile(optimizer=optimizer,\n",
        "                          loss='categorical_crossentropy',\n",
        "                          metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "            for epoch in range(epochs):\n",
        "                print(f\"Starting epoch {epoch+1}/{epochs}\")\n",
        "                history = model.fit(train_dataset, validation_data=val_dataset, epochs=1, verbose=1)\n",
        "                wandb.log({\n",
        "                    'epoch': epoch + 1,\n",
        "                    'train_loss': history.history['loss'][0],\n",
        "                    'train_accuracy': history.history['accuracy'][0],\n",
        "                    'train_precision': history.history['precision'][0],\n",
        "                    'train_recall': history.history['recall'][0],\n",
        "                    'val_loss': history.history['val_loss'][0],\n",
        "                    'val_accuracy': history.history['val_accuracy'][0],\n",
        "                    'val_precision': history.history['val_precision'][0],\n",
        "                    'val_recall': history.history['val_recall'][0],\n",
        "                })\n",
        "                print(f\"Completed epoch {epoch+1}/{epochs}. Validation Accuracy: {history.history['val_accuracy'][0]}\")\n",
        "\n",
        "            results.append({\n",
        "                'optimizer': optimizer_class.__name__,\n",
        "                'learning_rate': lr,\n",
        "                'accuracy': history.history['val_accuracy'][-1],\n",
        "                'precision': history.history['val_precision'][-1],\n",
        "                'recall': history.history['val_recall'][-1],\n",
        "                'loss': history.history['val_loss'][-1]\n",
        "            })\n",
        "            print(f\"Experiment completed with Learning Rate: {lr}, Optimizer: {optimizer_class.__name__}\\n\")\n",
        "            wandb.finish()\n",
        "    return results\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CeaV-aGbcw3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Execute Experiments\n",
        "scenarios = ['undersampling', 'oversampling', 'original']\n",
        "learning_rates = [0.001, 0.0001, 0.00001]\n",
        "optimizers = [tf.keras.optimizers.Adam, tf.keras.optimizers.SGD, tf.keras.optimizers.RMSprop]\n",
        "epochs = 20\n",
        "\n",
        "for scenario in scenarios:\n",
        "    print(f\"Ejecutando escenario: {scenario}\")\n",
        "    train_dataset = prepare_data_for_scenario(scenario, dir_covid, dir_pneumonia, dir_normal)\n",
        "    val_dataset = prepare_data_for_scenario(scenario, dir_covid, dir_pneumonia, dir_normal)\n",
        "    results = run_experiment(train_dataset, val_dataset, learning_rates, optimizers, epochs, scenario=scenario)\n",
        "    print(f'Resultados para el escenario: {scenario}')\n",
        "    for result in results:\n",
        "        print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981,
          "referenced_widgets": [
            "b9ffae47fd084a2c99fb55c45b0c0257",
            "79fb7c86c54e4d42a6e479e91d6623f7",
            "3e55477487e5458981357042aefd865d",
            "31f8e2ab07cf41d4b3542f992eaaa117",
            "f974825c0d5d4b2da301dc74e7e52f5c",
            "7eb85cdc856e4413818e699305d9e673",
            "62c8e14b62464e4e86b54cf1f25c4e5b",
            "2a63ddf2861742cf954b97e95cc813a5"
          ]
        },
        "id": "hdBOUlYUdgfm",
        "outputId": "721c25e8-3f55-43ff-b6be-72a8bc04caf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejecutando escenario: undersampling\n",
            "Cargando datos de /content/drive/MyDrive/Proyecto 1/Imagenes Proyecto 1/Procesadas/Covid/est_y_norm_Procesadas/ con etiqueta 0\n",
            "Total de archivos en /content/drive/MyDrive/Proyecto 1/Imagenes Proyecto 1/Procesadas/Covid/est_y_norm_Procesadas/: 3616\n",
            "Dimensiones de la imagen COVID-620.npy después de redimensionar: (299, 299, 3)\n",
            "Dimensiones de la imagen COVID-512.npy después de redimensionar: (299, 299, 3)\n",
            "Lote de datos dimensiones: (32, 299, 299, 3), Lote de etiquetas dimensiones: (32,)\n",
            "Dimensiones del dataset: (32, 32, 299, 299, 3), Dimensiones de las etiquetas: (32, 32, 3)\n",
            "Cargando datos de /content/drive/MyDrive/Proyecto 1/Imagenes Proyecto 1/Procesadas/Covid/est_y_norm_Procesadas/ con etiqueta 0\n",
            "Total de archivos en /content/drive/MyDrive/Proyecto 1/Imagenes Proyecto 1/Procesadas/Covid/est_y_norm_Procesadas/: 3616\n",
            "Dimensiones de la imagen COVID-3595.npy después de redimensionar: (299, 299, 3)\n",
            "Dimensiones de la imagen COVID-2410.npy después de redimensionar: (299, 299, 3)\n",
            "Lote de datos dimensiones: (32, 299, 299, 3), Lote de etiquetas dimensiones: (32,)\n",
            "Dimensiones del dataset: (32, 32, 299, 299, 3), Dimensiones de las etiquetas: (32, 32, 3)\n",
            "Starting experiments for scenario: undersampling\n",
            "\n",
            "Initializing experiment with Learning Rate: 0.001, Optimizer: Adam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:uaml6tgc) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9ffae47fd084a2c99fb55c45b0c0257"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">stilted-sponge-13</strong> at: <a href='https://wandb.ai/jd-lopez160-pontificia-universidad-javeriana/cnn-proyecto-1-ml/runs/uaml6tgc' target=\"_blank\">https://wandb.ai/jd-lopez160-pontificia-universidad-javeriana/cnn-proyecto-1-ml/runs/uaml6tgc</a><br/> View project at: <a href='https://wandb.ai/jd-lopez160-pontificia-universidad-javeriana/cnn-proyecto-1-ml' target=\"_blank\">https://wandb.ai/jd-lopez160-pontificia-universidad-javeriana/cnn-proyecto-1-ml</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240819_034419-uaml6tgc/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:uaml6tgc). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240819_034650-y2zygfz9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jd-lopez160-pontificia-universidad-javeriana/cnn-proyecto-1-ml/runs/y2zygfz9' target=\"_blank\">logical-dragon-14</a></strong> to <a href='https://wandb.ai/jd-lopez160-pontificia-universidad-javeriana/cnn-proyecto-1-ml' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/jd-lopez160-pontificia-universidad-javeriana/cnn-proyecto-1-ml' target=\"_blank\">https://wandb.ai/jd-lopez160-pontificia-universidad-javeriana/cnn-proyecto-1-ml</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/jd-lopez160-pontificia-universidad-javeriana/cnn-proyecto-1-ml/runs/y2zygfz9' target=\"_blank\">https://wandb.ai/jd-lopez160-pontificia-universidad-javeriana/cnn-proyecto-1-ml/runs/y2zygfz9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, None, 299, 299, 3), dtype=float32). Expected shape (None, 299, 299, 3), but input has incompatible shape (None, None, 299, 299, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, None, 299, 299, 3), dtype=float32)\n  • training=True\n  • mask=None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-52dd9c0fa140>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data_for_scenario\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_covid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_pneumonia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_normal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data_for_scenario\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_covid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_pneumonia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_normal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenario\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Resultados para el escenario: {scenario}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-6ef8cb479eda>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(train_dataset, val_dataset, learning_rates, optimizers, epochs, scenario)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Starting epoch {epoch+1}/{epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 wandb.log({\n\u001b[1;32m     26\u001b[0m                     \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36m_adjust_input_rank\u001b[0;34m(self, flat_inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m                     \u001b[0madjusted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0;34mf\"Invalid input shape for input {x}. Expected shape \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0;34mf\"{ref_shape}, but input has incompatible shape {x.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(None, None, 299, 299, 3), dtype=float32). Expected shape (None, 299, 299, 3), but input has incompatible shape (None, None, 299, 299, 3)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, None, 299, 299, 3), dtype=float32)\n  • training=True\n  • mask=None"
          ]
        }
      ]
    }
  ]
}